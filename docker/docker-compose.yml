version: '3.8'

services:
  # =============================================================================
  # Source Database: SQL Server 2019 with CDC enabled
  # =============================================================================
  sqlserver:
    image: mcr.microsoft.com/mssql/server:2019-latest
    container_name: cdc-sqlserver
    hostname: sqlserver
    environment:
      ACCEPT_EULA: Y
      SA_PASSWORD: ${SQLSERVER_PASSWORD:-YourStrong!Passw0rd}
      MSSQL_AGENT_ENABLED: ${SQLSERVER_AGENT_ENABLED:-true}
      MSSQL_PID: Developer
    ports:
      - "1433:1433"
    volumes:
      - sqlserver-data:/var/opt/mssql
    networks:
      - cdc-network
    healthcheck:
      test: /opt/mssql-tools/bin/sqlcmd -S localhost -U sa -P "$${SA_PASSWORD}" -Q "SELECT 1" || exit 1
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s

  # =============================================================================
  # Target Database: PostgreSQL 15
  # =============================================================================
  postgres:
    image: postgres:15-alpine
    container_name: cdc-postgres
    hostname: postgres
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-warehouse_target}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres_secure_password}
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --lc-collate=en_US.utf8 --lc-ctype=en_US.utf8"
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - cdc-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $${POSTGRES_USER} -d $${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # =============================================================================
  # Kafka Infrastructure: Zookeeper
  # =============================================================================
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.3
    container_name: cdc-zookeeper
    hostname: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SYNC_LIMIT: 2
      ZOOKEEPER_INIT_LIMIT: 5
    ports:
      - "2181:2181"
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data
      - zookeeper-logs:/var/lib/zookeeper/log
    networks:
      - cdc-network
    healthcheck:
      test: echo stat | nc localhost 2181
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # =============================================================================
  # Kafka Infrastructure: Kafka Broker 3.6+
  # =============================================================================
  kafka:
    image: confluentinc/cp-kafka:7.5.3
    container_name: cdc-kafka
    hostname: kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: ${KAFKA_ZOOKEEPER_CONNECT:-zookeeper:2181}
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: ${KAFKA_AUTO_CREATE_TOPICS_ENABLE:-true}
      KAFKA_NUM_PARTITIONS: ${KAFKA_NUM_PARTITIONS:-3}
      KAFKA_DEFAULT_REPLICATION_FACTOR: ${KAFKA_DEFAULT_REPLICATION_FACTOR:-1}
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_COMPRESSION_TYPE: lz4
      # JMX for Prometheus monitoring
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: kafka
    ports:
      - "9092:9092"
      - "29092:29092"
      - "9101:9101"
    volumes:
      - kafka-data:/var/lib/kafka/data
    networks:
      - cdc-network
    healthcheck:
      test: kafka-broker-api-versions --bootstrap-server localhost:9092 || exit 1
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 30s

  # =============================================================================
  # Kafka Infrastructure: Schema Registry 7.5+
  # =============================================================================
  schema-registry:
    image: confluentinc/cp-schema-registry:7.5.3
    container_name: cdc-schema-registry
    hostname: schema-registry
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: ${SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS:-kafka:9092}
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC: _schemas
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC_REPLICATION_FACTOR: 1
      SCHEMA_REGISTRY_SCHEMA_COMPATIBILITY_LEVEL: backward
    ports:
      - "8081:8081"
    networks:
      - cdc-network
    healthcheck:
      test: curl -f http://localhost:8081/subjects || exit 1
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s

  # =============================================================================
  # Kafka Connect Workers 3.6+ with Debezium and JDBC Sink
  # =============================================================================
  kafka-connect:
    image: confluentinc/cp-kafka-connect:7.5.3
    container_name: cdc-kafka-connect
    hostname: kafka-connect
    depends_on:
      kafka:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
      sqlserver:
        condition: service_healthy
      postgres:
        condition: service_healthy
      vault:
        condition: service_started
    environment:
      # Connect worker configuration
      CONNECT_BOOTSTRAP_SERVERS: ${CONNECT_BOOTSTRAP_SERVERS:-kafka:9092}
      CONNECT_REST_PORT: ${CONNECT_REST_PORT:-8083}
      CONNECT_REST_ADVERTISED_HOST_NAME: kafka-connect
      CONNECT_GROUP_ID: ${CONNECT_GROUP_ID:-cdc-connect-cluster}

      # Kafka topics for internal coordination
      CONNECT_CONFIG_STORAGE_TOPIC: ${CONNECT_CONFIG_STORAGE_TOPIC:-connect-configs}
      CONNECT_OFFSET_STORAGE_TOPIC: ${CONNECT_OFFSET_STORAGE_TOPIC:-connect-offsets}
      CONNECT_STATUS_STORAGE_TOPIC: ${CONNECT_STATUS_STORAGE_TOPIC:-connect-status}
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1

      # Converter configuration (Avro with Schema Registry)
      CONNECT_KEY_CONVERTER: ${CONNECT_KEY_CONVERTER:-io.confluent.connect.avro.AvroConverter}
      CONNECT_VALUE_CONVERTER: ${CONNECT_VALUE_CONVERTER:-io.confluent.connect.avro.AvroConverter}
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: ${CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL:-http://schema-registry:8081}
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: ${CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL:-http://schema-registry:8081}

      # Internal converter for Connect data
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter

      # Plugin path (will install connectors here)
      CONNECT_PLUGIN_PATH: ${CONNECT_PLUGIN_PATH:-/usr/share/java,/usr/share/confluent-hub-components}

      # Logging
      CONNECT_LOG4J_ROOT_LOGLEVEL: INFO
      CONNECT_LOG4J_LOGGERS: org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR

      # Task retry configuration with exponential backoff (T083)
      CONNECT_TASK_RESTART_POLICY_ENABLED: "true"
      CONNECT_TASK_RESTART_POLICY_MAX_RETRIES: "10"
      CONNECT_TASK_RESTART_POLICY_DELAY_MS: "5000"
      CONNECT_TASK_RESTART_POLICY_DELAY_MAX_MS: "300000"

      # JMX for Prometheus monitoring
      KAFKA_JMX_PORT: 9102
      KAFKA_JMX_HOSTNAME: kafka-connect

      # HashiCorp Vault configuration
      CONNECT_CONFIG_PROVIDERS: vault
      CONNECT_CONFIG_PROVIDERS_VAULT_CLASS: com.github.jcustenborder.kafka.config.vault.VaultConfigProvider
      CONNECT_CONFIG_PROVIDERS_VAULT_PARAM_VAULT_ADDR: ${VAULT_ADDR:-http://vault:8200}
      CONNECT_CONFIG_PROVIDERS_VAULT_PARAM_VAULT_TOKEN: ${VAULT_DEV_ROOT_TOKEN_ID:-dev-root-token}
    ports:
      - "8083:8083"
      - "9102:9102"
    volumes:
      - ./configs/debezium:/etc/kafka-connect/debezium
      - ./configs/kafka-connect:/etc/kafka-connect/jdbc
    networks:
      - cdc-network
    command:
      - bash
      - -c
      - |
        # Install Debezium SQL Server connector
        confluent-hub install --no-prompt debezium/debezium-connector-sqlserver:2.5.0

        # Install Confluent JDBC Sink connector
        confluent-hub install --no-prompt confluentinc/kafka-connect-jdbc:10.7.4

        # Install Vault config provider for secrets
        confluent-hub install --no-prompt jcustenborder/kafka-connect-vault:0.1.13

        # Start Kafka Connect
        /etc/confluent/docker/run
    healthcheck:
      test: curl -f http://localhost:8083/connectors || exit 1
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 90s

  # =============================================================================
  # HashiCorp Vault 1.15+ for secrets management
  # =============================================================================
  vault:
    image: hashicorp/vault:1.15
    container_name: cdc-vault
    hostname: vault
    environment:
      VAULT_DEV_ROOT_TOKEN_ID: ${VAULT_DEV_ROOT_TOKEN_ID:-dev-root-token}
      VAULT_DEV_LISTEN_ADDRESS: ${VAULT_DEV_LISTEN_ADDRESS:-0.0.0.0:8200}
      VAULT_ADDR: ${VAULT_API_ADDR:-http://0.0.0.0:8200}
    ports:
      - "8200:8200"
    volumes:
      - vault-data:/vault/data
      - vault-logs:/vault/logs
      - ./configs/vault:/vault/config
    networks:
      - cdc-network
    cap_add:
      - IPC_LOCK
    command: server -dev -dev-root-token-id=${VAULT_DEV_ROOT_TOKEN_ID:-dev-root-token}
    healthcheck:
      test: ["CMD", "vault", "status"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # =============================================================================
  # Prometheus 2.48+ for metrics collection
  # =============================================================================
  prometheus:
    image: prom/prometheus:v2.48.1
    container_name: cdc-prometheus
    hostname: prometheus
    depends_on:
      - kafka-connect
    volumes:
      - ./configs/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./configs/prometheus/alert-rules.yml:/etc/prometheus/alert-rules.yml
      - prometheus-data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - cdc-network
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
    healthcheck:
      test: wget --no-verbose --tries=1 --spider http://localhost:9090/-/healthy || exit 1
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # =============================================================================
  # Grafana 10.2+ for visualization dashboards
  # =============================================================================
  grafana:
    image: grafana/grafana:10.2.3
    container_name: cdc-grafana
    hostname: grafana
    depends_on:
      - prometheus
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_ADMIN_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:-admin_secure_password}
      GF_USERS_ALLOW_SIGN_UP: ${GRAFANA_ALLOW_SIGNUP:-false}
      GF_SERVER_ROOT_URL: http://localhost:3000
      GF_INSTALL_PLUGINS: ""
    volumes:
      - ./configs/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - grafana-data:/var/lib/grafana
    ports:
      - "3000:3000"
    networks:
      - cdc-network
    healthcheck:
      test: wget --no-verbose --tries=1 --spider http://localhost:3000/api/health || exit 1
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # =============================================================================
  # Jaeger 1.51+ for distributed tracing
  # =============================================================================
  jaeger:
    image: jaegertracing/all-in-one:1.51
    container_name: cdc-jaeger
    hostname: jaeger
    environment:
      COLLECTOR_ZIPKIN_HOST_PORT: :9411
      COLLECTOR_OTLP_ENABLED: true
    ports:
      - "5775:5775/udp"
      - "6831:6831/udp"
      - "6832:6832/udp"
      - "5778:5778"
      - "16686:16686"
      - "14250:14250"
      - "14268:14268"
      - "14269:14269"
      - "9411:9411"
    volumes:
      - jaeger-data:/tmp
    networks:
      - cdc-network
    healthcheck:
      test: wget --no-verbose --tries=1 --spider http://localhost:14269/ || exit 1
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # =============================================================================
  # PostgreSQL Exporter for Prometheus
  # =============================================================================
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:v0.15.0
    container_name: cdc-postgres-exporter
    hostname: postgres-exporter
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      DATA_SOURCE_NAME: "postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres_secure_password}@postgres:5432/${POSTGRES_DB:-warehouse_target}?sslmode=disable"
      PG_EXPORTER_EXTEND_QUERY_PATH: "/etc/postgres_exporter/queries.yaml"
    ports:
      - "9187:9187"
    volumes:
      - ./configs/prometheus/postgres-exporter-queries.yaml:/etc/postgres_exporter/queries.yaml
    networks:
      - cdc-network
    healthcheck:
      test: wget --no-verbose --tries=1 --spider http://localhost:9187/metrics || exit 1
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

# =============================================================================
# Networks
# =============================================================================
networks:
  cdc-network:
    driver: bridge
    name: cdc-network

# =============================================================================
# Volumes for data persistence
# =============================================================================
volumes:
  sqlserver-data:
    name: cdc-sqlserver-data
  postgres-data:
    name: cdc-postgres-data
  zookeeper-data:
    name: cdc-zookeeper-data
  zookeeper-logs:
    name: cdc-zookeeper-logs
  kafka-data:
    name: cdc-kafka-data
  vault-data:
    name: cdc-vault-data
  vault-logs:
    name: cdc-vault-logs
  prometheus-data:
    name: cdc-prometheus-data
  grafana-data:
    name: cdc-grafana-data
  jaeger-data:
    name: cdc-jaeger-data
